{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ðŸŽµ LoFi Music Generator - GPU Training on Colab\n",
    "\n",
    "**Train your LoFi music AI model with FREE GPU!**\n",
    "\n",
    "This notebook will:\n",
    "- âœ… Use Google's FREE GPU (100x faster than CPU)\n",
    "- âœ… Train on 178k MIDI files from Lakh dataset\n",
    "- âœ… Save trained model for download\n",
    "- âœ… Complete in 8-12 hours (not 43 days!)\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ IMPORTANT: Enable GPU First!\n",
    "\n",
    "1. Click **Runtime** â†’ **Change runtime type**\n",
    "2. Select **T4 GPU** or **GPU** from Hardware accelerator\n",
    "3. Click **Save**\n",
    "\n",
    "**Then run the cells below in order!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ðŸ“¦ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU is available\n",
    "import torch\n",
    "print(f\"ðŸ” GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ðŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âŒ NO GPU! Go to Runtime â†’ Change runtime type â†’ Select GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ’¾ Local Storage (Simplified!)\n\n**Training will use LOCAL Colab storage for speed:**\n- âœ… Faster training (no network overhead)\n- âœ… Checkpoints saved every 10,000 steps locally\n- âœ… Optional: Copy to OneDrive at the end\n\n**Note:** If Colab disconnects, checkpoints are lost. For long training runs, consider copying checkpoints periodically using the optional OneDrive cell below.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# OPTIONAL: Setup OneDrive for backup (skip if you don't need it)\n# This is ONLY needed if you want to backup checkpoints to OneDrive\n\n# Uncomment and run this cell if you want OneDrive backup:\n# !apt-get install -qq rclone\n# print(\"Run 'rclone config' on your local computer to get your config\")\n# print(\"Then paste it in the next cell\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ“¥ Clone Repository\n\n**IMPORTANT:** If you get authentication errors when cloning, choose ONE solution:\n\n### Option 1: Make Repository Public (Easiest)\n1. Go to https://github.com/andy-regulore/lofi\n2. Click **Settings** â†’ **General**\n3. Scroll to **Danger Zone** â†’ **Change repository visibility**\n4. Click **Change visibility** â†’ **Make public**\n\n### Option 2: Use Personal Access Token\n1. Go to https://github.com/settings/tokens\n2. Generate new token (classic) with **repo** scope\n3. Copy the token\n4. In the cell below, replace the clone command with:\n   ```\n   !git clone https://YOUR_TOKEN_HERE@github.com/andy-regulore/lofi.git\n   ```\n\nThen run the cell below â¬‡ï¸",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": "# Clone repository (handles both first run and re-runs after disconnect)\nimport os\n\nif os.path.exists('/content/lofi'):\n    print(\"ðŸ“ Repository already exists (from previous run)\")\n    print(\"Skipping clone, changing to directory...\\n\")\n    %cd /content/lofi\n    \n    # Pull latest changes just in case\n    print(\"ðŸ”„ Pulling latest changes...\")\n    !git pull origin main\nelse:\n    print(\"ðŸ“¥ Cloning repository for first time...\\n\")\n    # NOTE: If you get authentication errors, you need to either:\n    # 1. Make your repository PUBLIC on GitHub (Settings â†’ General â†’ Danger Zone â†’ Change visibility)\n    # 2. OR use a personal access token: !git clone https://YOUR_TOKEN@github.com/andy-regulore/lofi.git\n    \n    !git clone https://github.com/andy-regulore/lofi.git\n    %cd /content/lofi\n    \n    # Use main branch (all fixes are here)\n    !git checkout main\n\n# Verify we're in the right place\nprint(\"\\nâœ… Current directory:\")\n!pwd\nprint(\"\\nâœ… Checking for config.yaml:\")\n!ls -la config.yaml"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"ðŸ“¦ Installing dependencies (this takes 3-5 minutes)...\")\n",
    "!pip install -q torch transformers datasets accelerate\n",
    "!pip install -q miditok miditoolkit pretty_midi\n",
    "!pip install -q librosa soundfile scipy numpy pandas\n",
    "!pip install -q pyyaml scikit-learn tqdm tensorboard\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": "## ðŸ“‚ Step 2: Get Training Data\n\n**Choose ONE option:**\n- **Option A:** Download Lakh MIDI Dataset (176k files, ~20GB)\n- **Option B:** Upload your own MIDI files from OneDrive"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-lakh"
   },
   "outputs": [],
   "source": [
    "# OPTION A: Download Lakh MIDI Dataset (recommended)\n",
    "print(\"ðŸ“¥ Downloading Lakh MIDI Dataset (~20GB, takes 10-20 minutes)...\")\n",
    "!mkdir -p data/training\n",
    "!wget -q --show-progress http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
    "print(\"\\nðŸ“¦ Extracting dataset...\")\n",
    "!tar -xzf lmd_full.tar.gz -C data/training/\n",
    "!rm lmd_full.tar.gz\n",
    "print(\"âœ… Dataset ready!\")\n",
    "\n",
    "# Count files\n",
    "import os\n",
    "midi_count = sum(1 for root, dirs, files in os.walk('data/training') \n",
    "                 for f in files if f.endswith(('.mid', '.midi')))\n",
    "print(f\"\\nðŸŽµ Found {midi_count:,} MIDI files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": "# OPTION B: Use OneDrive (skip if you used Option A)\n# Uncomment if you have MIDI files in OneDrive\n\n# # Copy from your OneDrive to Colab (assumes OneDrive is already mounted)\n# !mkdir -p data/training\n# !cp -r /content/onedrive/your-midi-folder/* data/training/\n\n# # Count files\n# import os\n# midi_count = sum(1 for root, dirs, files in os.walk('data/training') \n#                  for f in files if f.endswith(('.mid', '.midi')))\n# print(f\"ðŸŽµ Found {midi_count:,} MIDI files\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## ðŸš€ Step 3: Train the Model!\n",
    "\n",
    "This will:\n",
    "1. Tokenize all MIDI files (1-2 hours)\n",
    "2. Train GPT-2 model (6-10 hours)\n",
    "3. Save trained model\n",
    "\n",
    "**Total time: 8-12 hours with GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-training"
   },
   "outputs": [],
   "source": "# Run training directly in Python with OneDrive checkpoint saving\nprint(\"ðŸš€ Starting training with checkpoint saving...\\n\")\nprint(\"ðŸ’¾ All progress will be saved to OneDrive!\")\nprint(\"If Colab disconnects, re-run this cell to resume from last checkpoint.\\n\")\n\n# Make sure we're in the right directory\nimport os\nimport pickle\nfrom pathlib import Path\nfrom multiprocessing import Pool, cpu_count\nfrom functools import partial\n\nif not Path('config.yaml').exists():\n    print(\"âŒ Error: Not in lofi directory!\")\n    print(\"Please run the repository clone cell first.\")\n    raise FileNotFoundError(\"config.yaml not found - wrong directory\")\n\nprint(f\"âœ… Working directory: {os.getcwd()}\\n\")\n\nimport yaml\nimport torch\nfrom src.tokenizer import LoFiTokenizer\nfrom src.model import ConditionedLoFiModel\nfrom src.trainer import LoFiTrainer\nfrom sklearn.model_selection import train_test_split\n\n# OneDrive paths\nDRIVE_DIR = '/content/onedrive/LoFi_Training'\nTOKENIZED_DATA_PATH = f'{DRIVE_DIR}/tokenized_data/sequences.pkl'\nCHECKPOINT_DIR = f'{DRIVE_DIR}/checkpoints'\nFINAL_MODEL_DIR = f'{DRIVE_DIR}/final_model'\n\n# Load config\nwith open('config.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\n# Override settings for Colab with OneDrive checkpointing\nconfig['training']['output_dir'] = CHECKPOINT_DIR\nconfig['training']['device'] = 'cuda'\nconfig['training']['fp16'] = True\nconfig['training']['num_epochs'] = 15  # User set to 15\nconfig['training']['batch_size'] = 4   # User set to 4\nconfig['training']['save_steps'] = 10000  # Save checkpoint every 10,000 steps\nconfig['training']['save_total_limit'] = 3  # Keep only last 3 checkpoints to save space\nconfig['data']['quality_filters']['require_drums'] = False\nconfig['data']['quality_filters']['min_tempo'] = 1\nconfig['data']['quality_filters']['max_tempo'] = 999\n\nprint(\"=\"*60)\nprint(\"PHASE 1: TOKENIZING MIDI FILES\")\nprint(\"=\"*60)\n\n# Check if we already have tokenized data in OneDrive\nif os.path.exists(TOKENIZED_DATA_PATH):\n    print(f\"\\nðŸŽ‰ Found existing tokenized data in OneDrive!\")\n    print(f\"Loading from: {TOKENIZED_DATA_PATH}\")\n    print(\"This saves hours of tokenization time!\\n\")\n    \n    with open(TOKENIZED_DATA_PATH, 'rb') as f:\n        saved_data = pickle.load(f)\n        token_sequences = saved_data['token_sequences']\n        vocab_size = saved_data['vocab_size']\n    \n    print(f\"âœ… Loaded {len(token_sequences):,} token sequences\")\n    print(f\"Vocabulary size: {vocab_size}\")\n    \nelse:\n    print(\"\\nðŸ’¾ No existing tokenized data found. Starting tokenization...\")\n    print(\"(This will be saved to OneDrive for future runs)\\n\")\n    \n    # Initialize tokenizer\n    tokenizer = LoFiTokenizer(config)\n    vocab_size = tokenizer.tokenizer.vocab_size\n    print(f\"Vocabulary size: {vocab_size}\")\n\n    # Find all MIDI files\n    training_dir = Path('data/training')\n    midi_files = list(training_dir.glob('**/*.mid')) + list(training_dir.glob('**/*.midi'))\n    \n    if len(midi_files) == 0:\n        print(\"\\n\" + \"=\"*60)\n        print(\"âŒ ERROR: NO MIDI FILES FOUND!\")\n        print(\"=\"*60)\n        print(\"\\nYou need to download training data first!\")\n        print(\"\\nðŸ“‹ STEPS TO FIX:\")\n        print(\"1. Scroll up to 'Step 2: Get Training Data'\")\n        print(\"2. Run either:\")\n        print(\"   - OPTION A: Download Lakh MIDI Dataset cell (recommended)\")\n        print(\"   - OPTION B: Upload your own MIDI files from OneDrive\")\n        print(\"3. Wait for download/upload to complete\")\n        print(\"4. Then come back and re-run this training cell\")\n        print(\"\\n\" + \"=\"*60)\n        raise ValueError(\"No MIDI files found! Please download training data first (see Step 2 above).\")\n    \n    print(f\"Found {len(midi_files):,} MIDI files\\n\")\n\n    # Parallel tokenization function\n    def tokenize_single_file(midi_file, config_dict):\n        \"\"\"Tokenize a single MIDI file (for parallel processing)\"\"\"\n        try:\n            # Create tokenizer instance for this process\n            tokenizer = LoFiTokenizer(config_dict)\n            \n            result = tokenizer.tokenize_midi(str(midi_file), check_quality=False)\n            if result and 'tokens' in result and len(result['tokens']) > 0:\n                chunks = tokenizer.chunk_sequence(result['tokens'])\n                if chunks:\n                    return ('success', chunks)\n                else:\n                    return ('fail', None)\n            else:\n                return ('fail', None)\n        except Exception as e:\n            return ('error', str(e)[:100])\n\n    # Use parallel processing to speed up tokenization\n    num_workers = cpu_count()\n    print(f\"âš¡ Using {num_workers} CPU cores for parallel tokenization\")\n    print(f\"   This should be ~{num_workers}x faster!\\n\")\n    \n    print(f\"Tokenizing {len(midi_files):,} files in parallel...\")\n    print(\"Progress updates every 1000 files:\\n\")\n\n    token_sequences = []\n    success_count = 0\n    fail_count = 0\n    error_count = 0\n    \n    # Process in batches for progress tracking\n    batch_size = 1000\n    \n    with Pool(num_workers) as pool:\n        for batch_start in range(0, len(midi_files), batch_size):\n            batch_end = min(batch_start + batch_size, len(midi_files))\n            batch_files = midi_files[batch_start:batch_end]\n            \n            # Process this batch in parallel\n            tokenize_func = partial(tokenize_single_file, config_dict=config)\n            results = pool.map(tokenize_func, batch_files)\n            \n            # Collect results\n            for result in results:\n                status, data = result\n                if status == 'success':\n                    token_sequences.extend(data)\n                    success_count += 1\n                elif status == 'fail':\n                    fail_count += 1\n                else:  # error\n                    error_count += 1\n                    if error_count <= 10:\n                        print(f\"  Error: {data}\")\n            \n            # Progress update\n            processed = batch_end\n            elapsed_pct = processed / len(midi_files) * 100\n            print(f\"  [{elapsed_pct:5.1f}%] Processed {processed:,}/{len(midi_files):,} files - \"\n                  f\"Success: {success_count:,}, Failed: {fail_count:,}\")\n\n    print(f\"\\nâœ… Tokenization complete!\")\n    print(f\"  Success: {success_count:,} files\")\n    print(f\"  Failed: {fail_count:,} files\")\n    print(f\"  Errors: {error_count:,} files\")\n    print(f\"  Generated: {len(token_sequences):,} token sequences\")\n\n    if len(token_sequences) == 0:\n        raise ValueError(\"No valid sequences generated. Check MIDI files.\")\n    \n    # Save tokenized data to OneDrive\n    print(f\"\\nðŸ’¾ Saving tokenized data to OneDrive...\")\n    print(f\"   Path: {TOKENIZED_DATA_PATH}\")\n    \n    with open(TOKENIZED_DATA_PATH, 'wb') as f:\n        pickle.dump({\n            'token_sequences': token_sequences,\n            'vocab_size': vocab_size\n        }, f)\n    \n    print(\"âœ… Tokenized data saved! Future runs will skip tokenization.\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PHASE 2: SPLITTING DATASET\")\nprint(\"=\"*60)\n\n# Split into train/eval\ntrain_sequences, eval_sequences = train_test_split(\n    token_sequences, test_size=0.1, random_state=42\n)\n\nprint(f\"Training sequences: {len(train_sequences):,}\")\nprint(f\"Evaluation sequences: {len(eval_sequences):,}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PHASE 3: INITIALIZING MODEL\")\nprint(\"=\"*60)\n\n# Initialize model\nmodel = ConditionedLoFiModel(config, vocab_size)\nmodel_info = model.get_model_info()\n\nprint(f\"Model: GPT-2\")\nprint(f\"Parameters: {model_info['total_parameters']:,} ({model_info['total_parameters']/1e6:.1f}M)\")\nprint(f\"Layers: {model_info['num_layers']}\")\nprint(f\"Context length: {model_info['context_length']}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PHASE 4: TRAINING MODEL\")\nprint(\"=\"*60)\nprint(f\"\\nðŸ’¾ Checkpoints will be saved to OneDrive every 10,000 steps\")\nprint(f\"ðŸ“ Location: {CHECKPOINT_DIR}\")\nprint(f\"\\nEpochs: {config['training']['num_epochs']}, Batch size: {config['training']['batch_size']}\")\nprint(\"\\nâš ï¸ If Colab disconnects, just re-run this cell - it will auto-resume from the last checkpoint!\\n\")\n\n# Check for existing checkpoints (just for user info - trainer handles this automatically)\nfrom transformers.trainer_utils import get_last_checkpoint\n\nexisting_checkpoint = None\nif os.path.exists(CHECKPOINT_DIR):\n    existing_checkpoint = get_last_checkpoint(CHECKPOINT_DIR)\n    if existing_checkpoint:\n        print(f\"ðŸ”„ Found existing checkpoint: {os.path.basename(existing_checkpoint)}\")\n        print(f\"   Training will resume from this checkpoint!\\n\")\n\n# Initialize trainer (it will auto-detect and resume from checkpoints)\ntrainer = LoFiTrainer(model, config, vocab_size)\n\n# Train! (trainer automatically resumes from last checkpoint if it exists)\nresults = trainer.train(train_sequences, eval_sequences)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… TRAINING COMPLETE!\")\nprint(\"=\"*60)\n\nprint(f\"\\nFinal metrics:\")\nprint(f\"  Train loss: {results['train_metrics'].get('train_loss', 'N/A')}\")\nprint(f\"  Eval loss: {results['eval_metrics'].get('eval_loss', 'N/A')}\")\n\n# Copy final model to separate directory in OneDrive\nprint(f\"\\nðŸ’¾ Copying final model to: {FINAL_MODEL_DIR}\")\nimport shutil\nif os.path.exists(FINAL_MODEL_DIR):\n    shutil.rmtree(FINAL_MODEL_DIR)\nshutil.copytree(CHECKPOINT_DIR, FINAL_MODEL_DIR)\n\nprint(f\"\\nâœ… Model saved to OneDrive!\")\nprint(f\"ðŸ“ Location: {FINAL_MODEL_DIR}\")\nprint(\"\\nðŸ‘‰ Run the download cell below to get your trained model!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## ðŸ“Š Step 4: Monitor Training (Optional)\n",
    "\n",
    "Run this in a separate cell to check progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": "# Load TensorBoard to monitor training from OneDrive\n%load_ext tensorboard\n%tensorboard --logdir /content/onedrive/LoFi_Training/checkpoints\n\n# You can also view logs locally if training hasn't started yet:\n# %tensorboard --logdir models/colab-trained/logs"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## ðŸ’¾ Step 5: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip-model"
   },
   "outputs": [],
   "source": "# Download trained model from OneDrive\nimport os\nfrom google.colab import files\n\nFINAL_MODEL_DIR = '/content/onedrive/LoFi_Training/final_model'\n\nif os.path.exists(FINAL_MODEL_DIR):\n    print(\"ðŸ“¦ Zipping your trained model from OneDrive...\")\n    print(f\"ðŸ“ Source: {FINAL_MODEL_DIR}\\n\")\n    \n    # Zip the model\n    !cd /content/onedrive/LoFi_Training && zip -r trained_lofi_model.zip final_model/\n    \n    print(\"\\nðŸ’¾ Downloading to your computer...\")\n    files.download('/content/onedrive/LoFi_Training/trained_lofi_model.zip')\n    \n    print(\"\\nâœ… Model downloaded!\")\n    print(\"\\nNext steps:\")\n    print(\"1. Unzip trained_lofi_model.zip\")\n    print(\"2. Copy the 'final_model' folder to your local lofi/models/ directory\")\n    print(\"3. Rename it to 'lofi-gpt2' (or update config.yaml)\")\n    print(\"4. Start generating music with your web UI!\")\nelse:\n    print(\"âŒ No trained model found in OneDrive!\")\n    print(f\"Expected location: {FINAL_MODEL_DIR}\")\n    print(\"\\nPlease run the training cell first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## ðŸŽµ Step 6: Test Generation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate"
   },
   "outputs": [],
   "source": "# Generate a test track (if scripts exist)\n# Note: You can also generate using the web UI after downloading the model\n\ntry:\n    !python scripts/04_generate.py \\\n        --config config.yaml \\\n        --model-path models/colab-trained \\\n        --output-dir output/test \\\n        --num-tracks 1 \\\n        --mood chill \\\n        --tempo 75\n\n    print(\"\\nâœ… Generated test track in output/test/\")\n\n    # Download the generated MIDI file\n    from google.colab import files\n    import os\n    if os.path.exists('output/test/midi'):\n        midi_files = [f for f in os.listdir('output/test/midi') if f.endswith('.mid')]\n        if midi_files:\n            files.download(f'output/test/midi/{midi_files[0]}')\n    else:\n        print(\"MIDI output directory not found\")\nexcept Exception as e:\n    print(f\"Generation failed: {e}\")\n    print(\"You can generate music using the web UI after downloading the model\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next"
   },
   "source": "## âœ… Next Steps\n\nAfter training completes:\n\n1. **Download the model** (Step 5 above)\n2. **Unzip** on your local machine\n3. **Place in** `lofi/models/lofi-gpt2/`\n4. **Generate music** using your local web UI!\n\n---\n\n### ðŸ’¾ OneDrive Checkpoint System\n\n**How it works:**\n- âœ… Tokenized MIDI data saved to OneDrive (1-2 hour savings!)\n- âœ… Model checkpoints saved every 10,000 steps\n- âœ… Keeps last 3 checkpoints (saves OneDrive space)\n- âœ… Auto-resumes from latest checkpoint\n\n**If Colab disconnects:**\n1. Wait for email notification (or check manually)\n2. Re-open this notebook\n3. Re-run the cells in order\n4. Training resumes exactly where it left off!\n\n**Your OneDrive will have:**\n```\nLoFi_Training/\n  â”œâ”€â”€ tokenized_data/\n  â”‚   â””â”€â”€ sequences.pkl (saved for future runs)\n  â”œâ”€â”€ checkpoints/\n  â”‚   â”œâ”€â”€ checkpoint-10000/\n  â”‚   â”œâ”€â”€ checkpoint-20000/\n  â”‚   â””â”€â”€ checkpoint-30000/\n  â””â”€â”€ final_model/ (ready to download)\n```\n\n---\n\n### ðŸŽ¯ Pro Tips:\n\n- **First run takes longest** - tokenization (1-2 hours) + training (6-10 hours)\n- **Subsequent runs are faster** - tokenized data is cached in OneDrive\n- **Training interrupted?** - Just re-run, it auto-resumes\n- **Want faster training?** - Reduce `num_epochs` from 10 to 5 in training cell\n- **Check progress anytime** - Use TensorBoard cell or check OneDrive folder\n- **OneDrive space low?** - Training uses ~5-10GB total\n\n---\n\n### âš¡ Troubleshooting:\n\n**\"Runtime disconnected\"**\n- Normal! Colab has 12-hour limit. Just re-run cells to resume.\n\n**\"Out of memory\"**\n- Reduce `batch_size` from 8 to 4 in training cell\n- Make sure you selected GPU (not CPU) in runtime settings\n\n**\"No MIDI files found\"**\n- Make sure Step 2 (download dataset) completed successfully\n- Check `data/training/` directory has files\n\n**\"Checkpoint not found\"**\n- First run won't have checkpoints - that's normal\n- Checkpoints appear after 10,000 training steps\n\n**\"OneDrive mount failed\"**\n- Check your rclone configuration in the setup cell\n- Make sure your token hasn't expired\n- Test with: `!rclone lsd onedrive:/`"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LoFi_Training_Colab.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}