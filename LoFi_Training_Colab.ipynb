{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ðŸŽµ LoFi Music Generator - GPU Training on Colab\n",
    "\n",
    "**Train your LoFi music AI model with FREE GPU!**\n",
    "\n",
    "This notebook will:\n",
    "- âœ… Use Google's FREE GPU (100x faster than CPU)\n",
    "- âœ… Train on 178k MIDI files from Lakh dataset\n",
    "- âœ… Save trained model for download\n",
    "- âœ… Complete in 8-12 hours (not 43 days!)\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ IMPORTANT: Enable GPU First!\n",
    "\n",
    "1. Click **Runtime** â†’ **Change runtime type**\n",
    "2. Select **T4 GPU** or **GPU** from Hardware accelerator\n",
    "3. Click **Save**\n",
    "\n",
    "**Then run the cells below in order!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ðŸ“¦ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU is available\n",
    "import torch\n",
    "print(f\"ðŸ” GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ðŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âŒ NO GPU! Go to Runtime â†’ Change runtime type â†’ Select GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/andy-regulore/lofi.git\n",
    "%cd lofi\n",
    "\n",
    "# Checkout the correct branch\n",
    "!git checkout claude/add-wav-upload-support-018ZUMDKbSCBaAvMDiN7XXU9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"ðŸ“¦ Installing dependencies (this takes 3-5 minutes)...\")\n",
    "!pip install -q torch transformers datasets accelerate\n",
    "!pip install -q miditok miditoolkit pretty_midi\n",
    "!pip install -q librosa soundfile scipy numpy pandas\n",
    "!pip install -q pyyaml scikit-learn tqdm tensorboard\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## ðŸ“‚ Step 2: Get Training Data\n",
    "\n",
    "**Choose ONE option:**\n",
    "- **Option A:** Download Lakh MIDI Dataset (176k files, ~20GB)\n",
    "- **Option B:** Upload your own MIDI files from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-lakh"
   },
   "outputs": [],
   "source": [
    "# OPTION A: Download Lakh MIDI Dataset (recommended)\n",
    "print(\"ðŸ“¥ Downloading Lakh MIDI Dataset (~20GB, takes 10-20 minutes)...\")\n",
    "!mkdir -p data/training\n",
    "!wget -q --show-progress http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz\n",
    "print(\"\\nðŸ“¦ Extracting dataset...\")\n",
    "!tar -xzf lmd_full.tar.gz -C data/training/\n",
    "!rm lmd_full.tar.gz\n",
    "print(\"âœ… Dataset ready!\")\n",
    "\n",
    "# Count files\n",
    "import os\n",
    "midi_count = sum(1 for root, dirs, files in os.walk('data/training') \n",
    "                 for f in files if f.endswith(('.mid', '.midi')))\n",
    "print(f\"\\nðŸŽµ Found {midi_count:,} MIDI files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# OPTION B: Use Google Drive (skip if you used Option A)\n",
    "# Uncomment if you have MIDI files in Google Drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Copy from your Google Drive to Colab\n",
    "# !mkdir -p data/training\n",
    "# !cp -r /content/drive/MyDrive/your-midi-folder/* data/training/\n",
    "\n",
    "# # Count files\n",
    "# import os\n",
    "# midi_count = sum(1 for root, dirs, files in os.walk('data/training') \n",
    "#                  for f in files if f.endswith(('.mid', '.midi')))\n",
    "# print(f\"ðŸŽµ Found {midi_count:,} MIDI files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## ðŸš€ Step 3: Train the Model!\n",
    "\n",
    "This will:\n",
    "1. Tokenize all MIDI files (1-2 hours)\n",
    "2. Train GPT-2 model (6-10 hours)\n",
    "3. Save trained model\n",
    "\n",
    "**Total time: 8-12 hours with GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-training"
   },
   "outputs": [],
   "source": "# Run training directly in Python (more reliable than scripts)\nprint(\"ðŸš€ Starting training...\\n\")\nprint(\"This will take 8-12 hours. You can close this tab and come back later.\")\nprint(\"Colab will email you when the runtime disconnects (after 12 hours max).\\n\")\n\n# Make sure we're in the right directory\nimport os\nfrom pathlib import Path\n\nif not Path('config.yaml').exists():\n    print(\"âŒ Error: Not in lofi directory!\")\n    print(\"Please run Cell 3 first to clone the repository.\")\n    print(\"Then make sure Cell 3 ran: %cd lofi\")\n    raise FileNotFoundError(\"config.yaml not found - wrong directory\")\n\nprint(f\"âœ… Working directory: {os.getcwd()}\\n\")\n\nimport yaml\nimport torch\nfrom src.tokenizer import LoFiTokenizer\nfrom src.model import ConditionedLoFiModel\nfrom src.trainer import LoFiTrainer\nfrom sklearn.model_selection import train_test_split\n\n# Load config\nwith open('config.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\n# Override settings for Colab\nconfig['training']['output_dir'] = 'models/colab-trained'\nconfig['training']['device'] = 'cuda'\nconfig['training']['fp16'] = True\nconfig['training']['num_epochs'] = 10  # Reduced from 50 to fit in 12 hours\nconfig['training']['batch_size'] = 8  # Larger batch for GPU\nconfig['data']['quality_filters']['require_drums'] = False\nconfig['data']['quality_filters']['min_tempo'] = 1\nconfig['data']['quality_filters']['max_tempo'] = 999\n\nprint(\"=\"*60)\nprint(\"PHASE 1: TOKENIZING MIDI FILES\")\nprint(\"=\"*60)\n\n# Initialize tokenizer\ntokenizer = LoFiTokenizer(config)\nvocab_size = tokenizer.tokenizer.vocab_size\nprint(f\"Vocabulary size: {vocab_size}\")\n\n# Find all MIDI files\ntraining_dir = Path('data/training')\nmidi_files = list(training_dir.glob('**/*.mid')) + list(training_dir.glob('**/*.midi'))\nprint(f\"\\nFound {len(midi_files):,} MIDI files\")\n\nif len(midi_files) == 0:\n    raise ValueError(\"No MIDI files found! Check data/training directory.\")\n\n# Tokenize files\ntoken_sequences = []\nsuccess_count = 0\nfail_count = 0\n\nprint(f\"\\nTokenizing {len(midi_files):,} files...\")\nprint(\"This will take 1-2 hours. Progress updates every 1000 files:\\n\")\n\nfor i, midi_file in enumerate(midi_files):\n    try:\n        # Progress updates\n        if (i + 1) % 1000 == 0:\n            print(f\"  Processed {i+1:,}/{len(midi_files):,} files ({(i+1)/len(midi_files)*100:.1f}%) - \"\n                  f\"Success: {success_count:,}, Failed: {fail_count:,}\")\n        \n        result = tokenizer.tokenize_midi(str(midi_file), check_quality=False)\n        if result and 'tokens' in result and len(result['tokens']) > 0:\n            chunks = tokenizer.chunk_sequence(result['tokens'])\n            if chunks:\n                token_sequences.extend(chunks)\n                success_count += 1\n            else:\n                fail_count += 1\n        else:\n            fail_count += 1\n    except Exception as e:\n        fail_count += 1\n        if fail_count <= 10:\n            print(f\"  Error with {midi_file.name}: {str(e)[:100]}\")\n        continue\n\nprint(f\"\\nâœ… Tokenization complete!\")\nprint(f\"  Success: {success_count:,} files\")\nprint(f\"  Failed: {fail_count:,} files\")\nprint(f\"  Generated: {len(token_sequences):,} token sequences\")\n\nif len(token_sequences) == 0:\n    raise ValueError(\"No valid sequences generated. Check MIDI files.\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PHASE 2: SPLITTING DATASET\")\nprint(\"=\"*60)\n\n# Split into train/eval\ntrain_sequences, eval_sequences = train_test_split(\n    token_sequences, test_size=0.1, random_state=42\n)\n\nprint(f\"Training sequences: {len(train_sequences):,}\")\nprint(f\"Evaluation sequences: {len(eval_sequences):,}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PHASE 3: INITIALIZING MODEL\")\nprint(\"=\"*60)\n\n# Initialize model\nmodel = ConditionedLoFiModel(config, vocab_size)\nmodel_info = model.get_model_info()\n\nprint(f\"Model: GPT-2\")\nprint(f\"Parameters: {model_info['total_parameters']:,} ({model_info['total_parameters']/1e6:.1f}M)\")\nprint(f\"Layers: {model_info['num_layers']}\")\nprint(f\"Context length: {model_info['context_length']}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PHASE 4: TRAINING MODEL\")\nprint(\"=\"*60)\nprint(\"\\nThis will take 6-10 hours on GPU.\")\nprint(\"You can monitor progress with TensorBoard (see next cell).\\n\")\n\n# Initialize trainer\ntrainer = LoFiTrainer(model, config, vocab_size)\n\n# Train!\nresults = trainer.train(train_sequences, eval_sequences)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… TRAINING COMPLETE!\")\nprint(\"=\"*60)\n\nprint(f\"\\nFinal metrics:\")\nprint(f\"  Train loss: {results['train_metrics'].get('train_loss', 'N/A')}\")\nprint(f\"  Eval loss: {results['eval_metrics'].get('eval_loss', 'N/A')}\")\nprint(f\"\\nModel saved to: {config['training']['output_dir']}\")\nprint(\"\\nðŸ‘‰ Run the next cell to download your trained model!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## ðŸ“Š Step 4: Monitor Training (Optional)\n",
    "\n",
    "Run this in a separate cell to check progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": "# Load TensorBoard to monitor training\n%load_ext tensorboard\n%tensorboard --logdir models/colab-trained/logs"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## ðŸ’¾ Step 5: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip-model"
   },
   "outputs": [],
   "source": "# Zip the trained model\n!zip -r trained_lofi_model.zip models/colab-trained/\n\n# Download to your computer\nfrom google.colab import files\nfiles.download('trained_lofi_model.zip')\n\nprint(\"âœ… Model downloaded!\")\nprint(\"\\nUnzip this file and place in your local lofi/models/ directory\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## ðŸŽµ Step 6: Test Generation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate"
   },
   "outputs": [],
   "source": "# Generate a test track (if scripts exist)\n# Note: You can also generate using the web UI after downloading the model\n\ntry:\n    !python scripts/04_generate.py \\\n        --config config.yaml \\\n        --model-path models/colab-trained \\\n        --output-dir output/test \\\n        --num-tracks 1 \\\n        --mood chill \\\n        --tempo 75\n\n    print(\"\\nâœ… Generated test track in output/test/\")\n\n    # Download the generated MIDI file\n    from google.colab import files\n    import os\n    if os.path.exists('output/test/midi'):\n        midi_files = [f for f in os.listdir('output/test/midi') if f.endswith('.mid')]\n        if midi_files:\n            files.download(f'output/test/midi/{midi_files[0]}')\n    else:\n        print(\"MIDI output directory not found\")\nexcept Exception as e:\n    print(f\"Generation failed: {e}\")\n    print(\"You can generate music using the web UI after downloading the model\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next"
   },
   "source": [
    "## âœ… Next Steps\n",
    "\n",
    "After training completes:\n",
    "\n",
    "1. **Download the model** (Step 5 above)\n",
    "2. **Unzip** on your local machine\n",
    "3. **Place in** `lofi/models/lofi-gpt2/`\n",
    "4. **Generate music** using your local web UI!\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Tips:\n",
    "\n",
    "- **Colab disconnects after 12 hours** - training will pause. Just re-run the training cell with `--resume` flag\n",
    "- **Want to continue later?** Mount Google Drive and save checkpoints there\n",
    "- **Training too long?** Reduce epochs in config.yaml (line 44)\n",
    "\n",
    "---\n",
    "\n",
    "### âš¡ Alternative: Reduce Training Size\n",
    "\n",
    "If you want faster results for testing, edit `config.yaml`:\n",
    "\n",
    "```yaml\n",
    "training:\n",
    "  num_epochs: 10  # Instead of 50\n",
    "  batch_size: 8   # Increase if you have GPU RAM\n",
    "```\n",
    "\n",
    "Or limit MIDI files by only extracting part of the dataset."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LoFi_Training_Colab.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}